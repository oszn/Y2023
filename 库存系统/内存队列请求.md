# 内存队列

感觉写完这个过程，像是在写一个同步mq一样。

`出发点`:库存的更新与流水过程，都是一个类似的过程，但是又是一个写操作频繁的过程，所以从减小数据库压力的角度出发，希望在内存层面，就能减小数据库锁竞争与写入压力。

`目的`：在内存阶段，接受大量的请求，将请求以队列的形式储存起来，然后将请求的内容进行压缩。

`例子`：

```
//id 代表商品id，num代表数目
//msg.id,msg.num|msg.id,msg.num|msg.id,msg.num|...|msg.id,msg.num;
1,1|1,2|1,2|2,3|2,5;
如果批量起来就是
1,5|2,8
外加一个流水list
这样可以批量插入。
```

`抽象`：

整个过程可以抽象出多个步骤。

1. 将库存变化消息输入，等待阻塞结果。
2. 将消息入队列，等待被消费整合。
3. 批量消费成功，将成功结果返回给阻塞等待的对象。



## 输入

输出一般就是一个订单的需要的商品id和数目，但是如果需要入队列，则需要一个回拨机制，也就是通知机制。本处使用的是锁机制。此处队列主要目的是防止多个线程对同一个资源的反复操作，所以需要在内存队列内进行预操作，避免冲突的发生。

```java
public class InventoryResponse {
    private Integer id;
    private Integer idx;
    private ReentrantLock lock;
    private Condition condition;
    private String result;
    private boolean isSuccess;
    ...	
```

消息体就这几个，在将内容如对后就开始等待结果。



## 队列

### 前言

将以上的东西传入后，将相同的商品id输出到同一个同步队列中，不同的id输出到不同的同步队列中。

架构分为2个部分，生产者与消费者，中间的管道使用阻塞队列，使用了10个管道来分割区域（相当于partition）此处借鉴了单线程消费的时候，如何才能进行优化的思想，也就是批量拉取+分区优化。

但目前还没找到合适的队列来做批量拉去，只能单点拉取，我觉得这个批量拉取的的想法不难，批量拉取，直接锁住整个对象，然后删除前100个对象的位置，然后在往后面加就行了。有必要需要重新写这个内存队列。

感觉我就想在写一个Kafka，这么想我就很牛的感觉，嘿嘿嘿，但肯定要考虑为什么不直接用Kafka。用了Kafka是异步，没办法同步拿到结果，时长不可控制。目前的库存基于异步同步数据库，所以Kafka来搞库存一点问题没有，但是我下一步想转化成同步的，因为目前的架构来说，异步同步的过程，非常依赖redis，那么redis g了整体的服务要么不可靠的，和部分不可用状态。

总结：同步数据库内存队列，异步数据Kafka。

而且：如果使用多个消息队列，可以直接在细节层面隐藏各个消息队列的差异性，把总结过程引入到逻辑层面，但是可用性需要考虑，比较内存队列g了，怎么处理是一个很大的问题。



### 结构

1. 生产者队列
2. partition，使用map
3. 消费者

使用线程池，整个线程池的任务就是将消息装入队列中即可。

有多个分区，不同的分区使用不同的idx进行路由，必须输入idx，否则相同的商品到了不同的分区是一件很危险的事情，会造成其他的分区线程对该分区的内容写入冲突。得不偿失。



消费者，可以看成一个pull逻辑，不过是定期的pull就是，200ms运行一次。









## 结果

单插入对比（避免表格出不来，就不使用表格了）

设置的一次性最大拉去量是200条。时间单位ms。

1000个线程情况模拟。

内存队列：3304。

直接插入：8716。

10000个线程的情况模拟。

内存队列：13758。

直接插入：36020。